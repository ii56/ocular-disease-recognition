{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c8595ee",
   "metadata": {},
   "source": [
    "# ODIR-5K Dataset Loader\n",
    "\n",
    "## Objective\n",
    "This notebook defines the PyTorch data pipeline used by all models.\n",
    "It:\n",
    "- Loads frozen `train.csv` and `val.csv`\n",
    "- Implements a custom PyTorch `Dataset`\n",
    "- Applies image preprocessing and augmentation\n",
    "- Builds CUDA-compatible `DataLoader` objects\n",
    "\n",
    "This layer is purely **engineering**, not data manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835481e8",
   "metadata": {},
   "source": [
    "## Section 1 - Import Required Libraries and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a68e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Display options\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eab0562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2050\n"
     ]
    }
   ],
   "source": [
    "# Detect CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8477775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve project root (notebooks â†’ project root)\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "TRAIN_CSV = PROCESSED_DIR / \"train.csv\"\n",
    "VAL_CSV = PROCESSED_DIR / \"val.csv\"\n",
    "\n",
    "IMAGE_ROOT = DATA_DIR / \"ODIR-5K\" / \"ODIR-5K\"\n",
    "\n",
    "assert TRAIN_CSV.exists(), \"train.csv not found!\"\n",
    "assert VAL_CSV.exists(), \"val.csv not found!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b039b484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 5600\n",
      "Validation samples: 1400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>eye</th>\n",
       "      <th>split</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>741_left.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3150_right.jpg</td>\n",
       "      <td>right</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3419_right.jpg</td>\n",
       "      <td>right</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4063_left.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4607_right.jpg</td>\n",
       "      <td>right</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name    eye  split  N  D  G  C  A  H  M  O\n",
       "0    741_left.jpg   left  train  0  0  0  0  0  0  1  0\n",
       "1  3150_right.jpg  right  train  1  0  0  0  0  0  0  0\n",
       "2  3419_right.jpg  right  train  1  0  0  0  0  0  0  0\n",
       "3   4063_left.jpg   left  train  0  1  0  0  0  0  0  0\n",
       "4  4607_right.jpg  right  train  0  1  0  0  0  0  0  0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CSV Files\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "val_df = pd.read_csv(VAL_CSV)\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2291e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Columns\n",
    "label_cols = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n",
    "NUM_CLASSES = len(label_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923194b9",
   "metadata": {},
   "source": [
    "## Section 2 - Image Transforms\n",
    "\n",
    "We use ImageNet-compatible normalization because all models use ImageNet-pretrained backbones. Augmentation is applied **only to training data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e730e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet normalization stats\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdff16e",
   "metadata": {},
   "source": [
    "## Section 3 - Custom PyTorch Dataset\n",
    "\n",
    "This dataset:\n",
    "- Loads fundus images\n",
    "- Returns `(image_tensor, multi_label_vector)`\n",
    "- Is reusable across all model architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e5ad29",
   "metadata": {},
   "source": [
    "## Create Dataset Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "880f8062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "class ODIRDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_root, transform=None):\n",
    "        # Reset index to ensure clean integer indexing\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "\n",
    "        # Root directory containing 'Training Images'\n",
    "        self.image_root = image_root\n",
    "\n",
    "        # Image transformations\n",
    "        self.transform = transform\n",
    "\n",
    "        # Cache labels for faster access (micro-optimization)\n",
    "        self.labels = self.df[label_cols].values.astype(np.float32)\n",
    "\n",
    "        # Cache image names\n",
    "        self.image_names = self.df[\"image_name\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Resolve image path (training images only)\n",
    "        image_path = self.image_root / \"Training Images\" / self.image_names[idx]\n",
    "\n",
    "        # Load and convert image to RGB\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert labels to tensor\n",
    "        labels = torch.from_numpy(self.labels[idx])\n",
    "\n",
    "        return image, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35160bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Datasets\n",
    "train_dataset = ODIRDataset(\n",
    "    dataframe=train_df,\n",
    "    image_root=IMAGE_ROOT,\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "val_dataset = ODIRDataset(\n",
    "    dataframe=val_df,\n",
    "    image_root=IMAGE_ROOT,\n",
    "    transform=val_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20dadc5",
   "metadata": {},
   "source": [
    "## Section 4 - Create DataLoaders\n",
    "\n",
    "We enable:\n",
    "- Shuffling for training\n",
    "- Pinned memory for CUDA\n",
    "- Configurable batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "591c167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ebbdf",
   "metadata": {},
   "source": [
    "## Section 5 - Sanity Check\n",
    "\n",
    "We verify:\n",
    "- Batch shapes\n",
    "- Label dimensions\n",
    "- CUDA compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3724926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch index: 0\n",
      "Image batch shape: torch.Size([16, 3, 224, 224])\n",
      "Label batch shape: torch.Size([16, 8])\n",
      "Images device: cuda:0\n",
      "Labels device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "    print(f\"Batch index: {batch_idx}\")\n",
    "    print(\"Image batch shape:\", images.shape)\n",
    "    print(\"Label batch shape:\", labels.shape)\n",
    "\n",
    "    # Move batch to GPU\n",
    "    images = images.to(device, non_blocking=True)\n",
    "    labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "    print(\"Images device:\", images.device)\n",
    "    print(\"Labels device:\", labels.device)\n",
    "\n",
    "    # Only test ONE batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d8e22",
   "metadata": {},
   "source": [
    "## Key Outcomes\n",
    "\n",
    "- PyTorch `Dataset` and `DataLoader` objects were successfully implemented\n",
    "- Image preprocessing and augmentation are standardized\n",
    "- Multi-label targets are correctly formatted for BCE-based losses\n",
    "- Data pipeline is CUDA-ready and reusable across models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
